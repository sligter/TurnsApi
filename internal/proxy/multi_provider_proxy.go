package proxy

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"strings"
	"time"

	"turnsapi/internal"
	"turnsapi/internal/database"
	"turnsapi/internal/keymanager"
	"turnsapi/internal/logger"
	"turnsapi/internal/providers"
	"turnsapi/internal/proxykey"
	"turnsapi/internal/ratelimit"
	"turnsapi/internal/router"

	"github.com/gin-gonic/gin"
)

// MultiProviderProxy å¤šæä¾›å•†ä»£ç†
type MultiProviderProxy struct {
	config          *internal.Config
	keyManager      *keymanager.MultiGroupKeyManager
	proxyKeyManager *proxykey.Manager
	providerManager *providers.ProviderManager
	providerRouter  *router.ProviderRouter
	requestLogger   *logger.RequestLogger
	rpmLimiter      *ratelimit.RPMLimiter
	database        *database.GroupsDB
}

func hasHeaderKey(m map[string]string, key string) bool {
	for k := range m {
		if strings.EqualFold(k, key) {
			return true
		}
	}
	return false
}

func (p *MultiProviderProxy) applyForwardHeaders(c *gin.Context, cfg *providers.ProviderConfig) {
	if c == nil || cfg == nil {
		return
	}
	if cfg.Headers == nil {
		cfg.Headers = make(map[string]string)
	}

	// Forward a small allowlist of non-sensitive headers that some OpenAI-compatible gateways require.
	// Prefer incoming `HTTP-Referer`, fallback to standard `Referer`.
	if !hasHeaderKey(cfg.Headers, "HTTP-Referer") {
		ref := strings.TrimSpace(c.GetHeader("HTTP-Referer"))
		if ref == "" {
			ref = strings.TrimSpace(c.GetHeader("Referer"))
		}
		if ref != "" {
			cfg.Headers["HTTP-Referer"] = ref
		}
	}

	if !hasHeaderKey(cfg.Headers, "Referer") {
		if ref := strings.TrimSpace(c.GetHeader("Referer")); ref != "" {
			cfg.Headers["Referer"] = ref
		}
	}

	if !hasHeaderKey(cfg.Headers, "Origin") {
		if origin := strings.TrimSpace(c.GetHeader("Origin")); origin != "" {
			cfg.Headers["Origin"] = origin
		}
	}

	if !hasHeaderKey(cfg.Headers, "X-Title") {
		if v := strings.TrimSpace(c.GetHeader("X-Title")); v != "" {
			cfg.Headers["X-Title"] = v
		}
	}

	// Browser-like headers (optional; forwarded only when present).
	for _, h := range []string{
		"Accept",
		"Accept-Language",
		"Priority",
		"Sec-CH-UA",
		"Sec-CH-UA-Mobile",
		"Sec-CH-UA-Platform",
		"Sec-Fetch-Dest",
		"Sec-Fetch-Mode",
		"Sec-Fetch-Site",
		"User-Agent",
	} {
		if hasHeaderKey(cfg.Headers, h) {
			continue
		}
		if v := strings.TrimSpace(c.GetHeader(h)); v != "" {
			cfg.Headers[h] = v
		}
	}
}

// NewMultiProviderProxy åˆ›å»ºå¤šæä¾›å•†ä»£ç†
func NewMultiProviderProxy(
	config *internal.Config,
	keyManager *keymanager.MultiGroupKeyManager,
	requestLogger *logger.RequestLogger,
) *MultiProviderProxy {
	// åˆ›å»ºæä¾›å•†ç®¡ç†å™¨
	factory := providers.NewDefaultProviderFactory()
	providerManager := providers.NewProviderManager(factory)

	// åˆ›å»ºæä¾›å•†è·¯ç”±å™¨
	providerRouter := router.NewProviderRouter(config, providerManager)

	// åˆ›å»ºRPMé™åˆ¶å™¨å¹¶åˆå§‹åŒ–åˆ†ç»„é™åˆ¶
	rpmLimiter := ratelimit.NewRPMLimiter()
	if config.UserGroups != nil {
		for groupID, group := range config.UserGroups {
			if group.RPMLimit > 0 {
				rpmLimiter.SetLimit(groupID, group.RPMLimit)
			}
		}
	}

	return &MultiProviderProxy{
		config:          config,
		keyManager:      keyManager,
		providerManager: providerManager,
		providerRouter:  providerRouter,
		requestLogger:   requestLogger,
		rpmLimiter:      rpmLimiter,
	}
}

// NewMultiProviderProxyWithProxyKey åˆ›å»ºå¸¦ä»£ç†å¯†é’¥ç®¡ç†å™¨çš„å¤šæä¾›å•†ä»£ç†
func NewMultiProviderProxyWithProxyKey(
	config *internal.Config,
	keyManager *keymanager.MultiGroupKeyManager,
	proxyKeyManager *proxykey.Manager,
	requestLogger *logger.RequestLogger,
) *MultiProviderProxy {
	factory := providers.NewDefaultProviderFactory()
	providerManager := providers.NewProviderManager(factory)
	providerRouter := router.NewProviderRouterWithProxyKey(config, providerManager, proxyKeyManager)

	// åˆ›å»ºRPMé™åˆ¶å™¨
	rpmLimiter := ratelimit.NewRPMLimiter()

	// ä¸ºæ¯ä¸ªåˆ†ç»„è®¾ç½®RPMé™åˆ¶
	for groupID, group := range config.UserGroups {
		if group.RPMLimit > 0 {
			rpmLimiter.SetLimit(groupID, group.RPMLimit)
		}
	}

	// åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
	groupsDB, err := database.NewGroupsDBWithConfig(config.Database)
	if err != nil {
		log.Printf("Failed to initialize database for proxy: %v", err)
	}

	return &MultiProviderProxy{
		config:          config,
		keyManager:      keyManager,
		proxyKeyManager: proxyKeyManager,
		providerManager: providerManager,
		providerRouter:  providerRouter,
		requestLogger:   requestLogger,
		rpmLimiter:      rpmLimiter,
		database:        groupsDB,
	}
}

// RemoveProvider ä»æä¾›å•†ç®¡ç†å™¨ä¸­ç§»é™¤åˆ†ç»„
func (mp *MultiProviderProxy) RemoveProvider(groupID string) {
	mp.providerManager.RemoveProvider(groupID)
	// åŒæ—¶ç§»é™¤RPMé™åˆ¶
	mp.rpmLimiter.RemoveLimit(groupID)
}

// UpdateRPMLimit æ›´æ–°åˆ†ç»„çš„RPMé™åˆ¶
func (mp *MultiProviderProxy) UpdateRPMLimit(groupID string, limit int) {
	mp.rpmLimiter.SetLimit(groupID, limit)
}

// GetRPMStats è·å–RPMç»Ÿè®¡ä¿¡æ¯
func (mp *MultiProviderProxy) GetRPMStats() map[string]map[string]int {
	return mp.rpmLimiter.GetAllStats()
}

// shouldUseNativeResponse æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨åŸç”Ÿå“åº”æ ¼å¼
func (p *MultiProviderProxy) shouldUseNativeResponse(groupID string, c *gin.Context) bool {
	// æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨åŸç”Ÿå“åº”
	if forceNative, exists := c.Get("force_native_response"); exists {
		if force, ok := forceNative.(bool); ok && force {
			return true
		}
	}

	// æ£€æŸ¥åˆ†ç»„é…ç½®
	if p.config.UserGroups == nil {
		return false
	}

	group, exists := p.config.UserGroups[groupID]
	if !exists {
		return false
	}

	return group.UseNativeResponse
}

// getNativeResponse è·å–æä¾›å•†çš„åŸç”Ÿå“åº”æ ¼å¼
func (p *MultiProviderProxy) getNativeResponse(provider providers.Provider, standardResponse *providers.ChatCompletionResponse) (interface{}, error) {
	// æ ¹æ®æä¾›å•†ç±»å‹è¿”å›ç›¸åº”çš„åŸç”Ÿæ ¼å¼
	switch provider.GetProviderType() {
	case "gemini":
		return p.convertToGeminiNativeResponse(standardResponse)
	case "anthropic":
		return p.convertToAnthropicNativeResponse(standardResponse)
	case "openai", "azure_openai":
		// OpenAIæ ¼å¼æœ¬èº«å°±æ˜¯æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è¿”å›
		return standardResponse, nil
	default:
		// å¯¹äºæœªçŸ¥æä¾›å•†ï¼Œè¿”å›æ ‡å‡†æ ¼å¼
		return standardResponse, nil
	}
}

// convertToGeminiNativeResponse è½¬æ¢ä¸ºGeminiåŸç”Ÿå“åº”æ ¼å¼
func (p *MultiProviderProxy) convertToGeminiNativeResponse(response *providers.ChatCompletionResponse) (interface{}, error) {
	// æ„é€ GeminiåŸç”Ÿå“åº”æ ¼å¼
	nativeResponse := map[string]interface{}{
		"candidates": []map[string]interface{}{
			{
				"content": map[string]interface{}{
					"parts": []map[string]interface{}{
						{
							"text": response.Choices[0].Message.Content,
						},
					},
					"role": "model",
				},
				"finishReason": response.Choices[0].FinishReason,
				"index":        response.Choices[0].Index,
			},
		},
		"usageMetadata": map[string]interface{}{
			"promptTokenCount":     response.Usage.PromptTokens,
			"candidatesTokenCount": response.Usage.CompletionTokens,
			"totalTokenCount":      response.Usage.TotalTokens,
		},
	}

	return nativeResponse, nil
}

// convertToAnthropicNativeResponse è½¬æ¢ä¸ºAnthropicåŸç”Ÿå“åº”æ ¼å¼
func (p *MultiProviderProxy) convertToAnthropicNativeResponse(response *providers.ChatCompletionResponse) (interface{}, error) {
	// æ„é€ AnthropicåŸç”Ÿå“åº”æ ¼å¼
	nativeResponse := map[string]interface{}{
		"id":   response.ID,
		"type": "message",
		"role": "assistant",
		"content": []map[string]interface{}{
			{
				"type": "text",
				"text": response.Choices[0].Message.Content,
			},
		},
		"model":       response.Model,
		"stop_reason": response.Choices[0].FinishReason,
		"usage": map[string]interface{}{
			"input_tokens":  response.Usage.PromptTokens,
			"output_tokens": response.Usage.CompletionTokens,
		},
	}

	return nativeResponse, nil
}

// HandleChatCompletion å¤„ç†èŠå¤©å®Œæˆè¯·æ±‚
func (p *MultiProviderProxy) HandleChatCompletion(c *gin.Context) {
	startTime := time.Now()

	// è§£æè¯·æ±‚ - ä¼˜å…ˆä»ä¸Šä¸‹æ–‡è·å–é¢„è®¾è¯·æ±‚
	var req providers.ChatCompletionRequest
	if presetReq, exists := c.Get("chat_request"); exists {
		if chatReq, ok := presetReq.(*providers.ChatCompletionRequest); ok {
			req = *chatReq
		} else {
			log.Printf("Invalid preset request type")
			c.JSON(http.StatusInternalServerError, gin.H{
				"error": gin.H{
					"message": "Internal server error",
					"type":    "internal_error",
				},
			})
			return
		}
	} else {
		bodyBytes, err := io.ReadAll(c.Request.Body)
		if err != nil {
			log.Printf("Failed to read request body: %v", err)
			c.JSON(http.StatusBadRequest, gin.H{
				"error": gin.H{
					"message": "Invalid request format",
					"type":    "invalid_request_error",
					"code":    "invalid_json",
				},
			})
			return
		}
		c.Request.Body = io.NopCloser(bytes.NewBuffer(bodyBytes))

		var raw map[string]interface{}
		if err := json.Unmarshal(bodyBytes, &raw); err != nil {
			log.Printf("Failed to parse request json: %v", err)
			c.JSON(http.StatusBadRequest, gin.H{
				"error": gin.H{
					"message": "Invalid request format",
					"type":    "invalid_request_error",
					"code":    "invalid_json",
				},
			})
			return
		}

		if err := json.Unmarshal(bodyBytes, &req); err != nil {
			log.Printf("Failed to parse request: %v", err)
			c.JSON(http.StatusBadRequest, gin.H{
				"error": gin.H{
					"message": "Invalid request format",
					"type":    "invalid_request_error",
					"code":    "invalid_json",
				},
			})
			return
		}

		if len(raw) > 0 {
			knownKeys := map[string]struct{}{
				"model":               {},
				"messages":            {},
				"temperature":         {},
				"max_tokens":          {},
				"stream":              {},
				"top_p":               {},
				"stop":                {},
				"tools":               {},
				"tool_choice":         {},
				"parallel_tool_calls": {},
			}

			extra := make(map[string]interface{})
			for k, v := range raw {
				if _, ok := knownKeys[k]; ok {
					continue
				}
				extra[k] = v
			}

			if len(extra) > 0 {
				req.Extra = extra
			}
		}
	}

	// æ£€æŸ¥å¿…éœ€å­—æ®µ
	if req.Model == "" {
		c.JSON(http.StatusBadRequest, gin.H{
			"error": gin.H{
				"message": "Model is required",
				"type":    "invalid_request_error",
				"code":    "missing_model",
			},
		})
		return
	}

	if len(req.Messages) == 0 {
		c.JSON(http.StatusBadRequest, gin.H{
			"error": gin.H{
				"message": "Messages are required",
				"type":    "invalid_request_error",
				"code":    "missing_messages",
			},
		})
		return
	}

	// è·å–ä»£ç†å¯†é’¥ä¿¡æ¯ä»¥æ£€æŸ¥æƒé™
	var allowedGroups []string
	var proxyKeyID string
	if keyInfo, exists := c.Get("key_info"); exists {
		if proxyKey, ok := keyInfo.(*logger.ProxyKey); ok {
			allowedGroups = proxyKey.AllowedGroups
			proxyKeyID = proxyKey.ID
		}
	}

	// è·¯ç”±åˆ°åˆé€‚çš„æä¾›å•†
	routeReq := &router.RouteRequest{
		Model:         req.Model,
		AllowedGroups: allowedGroups, // ä¼ é€’ä»£ç†å¯†é’¥çš„æƒé™é™åˆ¶
		ProxyKeyID:    proxyKeyID,    // ä¼ é€’ä»£ç†å¯†é’¥IDç”¨äºåˆ†ç»„é€‰æ‹©
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾å¼æŒ‡å®šçš„æä¾›å•†åˆ†ç»„
	if providerGroup := c.GetHeader("X-Provider-Group"); providerGroup != "" {
		routeReq.ProviderGroup = providerGroup
	}

	// æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶æŒ‡å®šæä¾›å•†ç±»å‹
	if targetProvider, exists := c.Get("target_provider"); exists {
		if providerType, ok := targetProvider.(string); ok {
			routeReq.ForceProviderType = providerType
		}
	}

	// ä½¿ç”¨æ™ºèƒ½è·¯ç”±é‡è¯•æœºåˆ¶
	success := p.handleRequestWithRetry(c, &req, routeReq, startTime)
	if !success {
		// å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼Œè¿”å›é”™è¯¯
		c.JSON(http.StatusBadGateway, gin.H{
			"error": gin.H{
				"message": "All provider groups failed to process the request",
				"type":    "service_unavailable",
				"code":    "all_providers_failed",
			},
		})
	}
}

// handleRequestWithRetry å¤„ç†è¯·æ±‚å¹¶æ”¯æŒæ™ºèƒ½é‡è¯•
func (p *MultiProviderProxy) handleRequestWithRetry(
	c *gin.Context,
	req *providers.ChatCompletionRequest,
	routeReq *router.RouteRequest,
	startTime time.Time,
) bool {
	// æ™ºèƒ½æ•…éšœè½¬ç§»ï¼šä¼˜å…ˆåœ¨åˆ†ç»„é—´è½®æ¢é‡è¯•ï¼Œæœ€å¤šé‡è¯•3ä¸ªå¯†é’¥
	return p.handleRequestWithSmartFailover(c, req, routeReq, startTime)
}

// handleRequestWithSmartFailover å®ç°æ™ºèƒ½æ•…éšœè½¬ç§»æœºåˆ¶
// æ–°ç­–ç•¥ï¼šä¼˜å…ˆåœ¨åˆ†ç»„é—´è½®æ¢é‡è¯•ï¼Œæœ€åå†åœ¨åˆ†ç»„å†…é‡è¯•ï¼Œæœ€å¤šé‡è¯•3ä¸ªå¯†é’¥å³åœæ­¢
func (p *MultiProviderProxy) handleRequestWithSmartFailover(
	c *gin.Context,
	req *providers.ChatCompletionRequest,
	routeReq *router.RouteRequest,
	startTime time.Time,
) bool {
	// è·å–æ”¯æŒè¯¥æ¨¡å‹çš„æ‰€æœ‰åˆ†ç»„
	candidateGroups := p.providerRouter.GetGroupsForModel(req.Model, routeReq.AllowedGroups)
	if len(candidateGroups) == 0 {
		log.Printf("æ²¡æœ‰å¯ç”¨åˆ†ç»„æ”¯æŒæ¨¡å‹ %s", req.Model)
		return false
	}

	log.Printf("å¼€å§‹åˆ†ç»„é—´è½®æ¢é‡è¯•ï¼Œæ”¯æŒæ¨¡å‹ %s çš„åˆ†ç»„: %v", req.Model, candidateGroups)

	// ä½¿ç”¨æ–°çš„åˆ†ç»„é—´è½®æ¢é‡è¯•ç­–ç•¥ï¼Œæœ€å¤šé‡è¯•3ä¸ªå¯†é’¥
	return p.tryGroupRotationWithLimit(c, req, routeReq, candidateGroups, startTime, 3)
}

// tryGroupRotationWithLimit åˆ†ç»„é—´è½®æ¢é‡è¯•ï¼Œæœ€å¤šé‡è¯•æŒ‡å®šæ•°é‡çš„å¯†é’¥
func (p *MultiProviderProxy) tryGroupRotationWithLimit(
	c *gin.Context,
	req *providers.ChatCompletionRequest,
	routeReq *router.RouteRequest,
	candidateGroups []string,
	startTime time.Time,
	maxRetries int,
) bool {
	// ä¸ºæ¯ä¸ªåˆ†ç»„å‡†å¤‡å¯†é’¥åˆ—è¡¨
	groupKeys := make(map[string][]string)
	totalAvailableKeys := 0

	for _, groupID := range candidateGroups {
		// æ£€æŸ¥RPMé™åˆ¶
		if !p.rpmLimiter.Allow(groupID) {
			log.Printf("åˆ†ç»„ %s è¶…å‡ºRPMé™åˆ¶ï¼Œè·³è¿‡", groupID)
			continue
		}

		// è·å–åˆ†ç»„çš„æ‰€æœ‰å¯ç”¨å¯†é’¥çŠ¶æ€
		groupStatus, exists := p.keyManager.GetGroupStatus(groupID)
		if !exists {
			log.Printf("åˆ†ç»„ %s ä¸å­˜åœ¨æˆ–æœªå¯ç”¨ï¼Œè·³è¿‡", groupID)
			continue
		}

		groupInfo := groupStatus.(map[string]interface{})
		keyStatuses, ok := groupInfo["key_statuses"].(map[string]*keymanager.KeyStatus)
		if !ok {
			log.Printf("æ— æ³•è·å–åˆ†ç»„ %s çš„å¯†é’¥çŠ¶æ€ï¼Œè·³è¿‡", groupID)
			continue
		}

		// æŒ‰ä¼˜å…ˆçº§æ’åºå¯†é’¥ï¼šæ´»è·ƒä¸”æœ‰æ•ˆçš„å¯†é’¥ä¼˜å…ˆ
		sortedKeys := p.sortKeysByPriority(keyStatuses)
		if len(sortedKeys) > 0 {
			groupKeys[groupID] = sortedKeys
			totalAvailableKeys += len(sortedKeys)

			// æ˜¾ç¤ºå¯†é’¥è¯¦ç»†ä¿¡æ¯
			keyDetails := make([]string, len(sortedKeys))
			for i, key := range sortedKeys {
				keyDetails[i] = p.maskKey(key)
			}
			log.Printf("åˆ†ç»„ %s æœ‰ %d ä¸ªå¯ç”¨å¯†é’¥: [%s]", groupID, len(sortedKeys), strings.Join(keyDetails, ", "))
		} else {
			log.Printf("åˆ†ç»„ %s æ²¡æœ‰å¯ç”¨å¯†é’¥ï¼Œè·³è¿‡ï¼ˆæ€»å¯†é’¥æ•°: %dï¼‰", groupID, len(keyStatuses))
		}
	}

	if len(groupKeys) == 0 {
		log.Printf("æ²¡æœ‰å¯ç”¨çš„åˆ†ç»„å’Œå¯†é’¥")
		return false
	}

	// è·å–å®é™…å¯ç”¨çš„åˆ†ç»„åˆ—è¡¨ï¼ˆæœ‰å¯†é’¥çš„åˆ†ç»„ï¼‰
	availableGroups := make([]string, 0, len(groupKeys))
	for _, groupID := range candidateGroups {
		if _, exists := groupKeys[groupID]; exists {
			availableGroups = append(availableGroups, groupID)
		}
	}

	log.Printf("å¼€å§‹åˆ†ç»„é—´è½®æ¢é‡è¯•ï¼Œå€™é€‰åˆ†ç»„: %vï¼Œå¯ç”¨åˆ†ç»„: %vï¼Œæ€»å¯ç”¨å¯†é’¥: %dï¼Œæœ€å¤šé‡è¯• %d ä¸ªå¯†é’¥",
		candidateGroups, availableGroups, totalAvailableKeys, maxRetries)

	// åˆ†ç»„é—´è½®æ¢é‡è¯•é€»è¾‘
	retryCount := 0
	keyIndex := 0

	for retryCount < maxRetries {
		// æ£€æŸ¥å½“å‰è½®æ¬¡æ˜¯å¦è¿˜æœ‰å¯ç”¨å¯†é’¥
		hasKeysInCurrentRound := false
		for _, groupID := range availableGroups {
			if keys, exists := groupKeys[groupID]; exists && keyIndex < len(keys) {
				hasKeysInCurrentRound = true
				break
			}
		}

		if !hasKeysInCurrentRound {
			log.Printf("å½“å‰è½®æ¬¡ %d æ²¡æœ‰ä»»ä½•åˆ†ç»„æœ‰å¯ç”¨å¯†é’¥ï¼Œåœæ­¢é‡è¯•", keyIndex+1)
			break
		}

		// è½®æ¢å°è¯•æ¯ä¸ªå¯ç”¨åˆ†ç»„çš„ç¬¬keyIndexä¸ªå¯†é’¥
		for _, groupID := range availableGroups {
			keys, exists := groupKeys[groupID]
			if !exists || keyIndex >= len(keys) {
				log.Printf("åˆ†ç»„ %s æ²¡æœ‰ç¬¬ %d ä¸ªå¯†é’¥ï¼Œè·³è¿‡", groupID, keyIndex+1)
				continue // è¯¥åˆ†ç»„æ²¡æœ‰æ›´å¤šå¯†é’¥
			}

			apiKey := keys[keyIndex]
			retryCount++

			log.Printf("è½®æ¢é‡è¯•ç¬¬ %d/%d æ¬¡ï¼šå°è¯•åˆ†ç»„ %s çš„ç¬¬ %d ä¸ªå¯†é’¥: %s",
				retryCount, maxRetries, groupID, keyIndex+1, p.maskKey(apiKey))

			// ä¸ºè¯¥åˆ†ç»„åˆ›å»ºè·¯ç”±è¯·æ±‚
			groupRouteReq := &router.RouteRequest{
				Model:         req.Model,
				ProviderGroup: groupID,
				AllowedGroups: routeReq.AllowedGroups,
				ProxyKeyID:    routeReq.ProxyKeyID,
			}

			// è·å–è¯¥åˆ†ç»„çš„è·¯ç”±ç»“æœ
			routeResult, err := p.providerRouter.RouteWithRetry(groupRouteReq)
			if err != nil {
				log.Printf("åˆ†ç»„ %s è·¯ç”±å¤±è´¥: %vï¼Œè·³è¿‡è¯¥åˆ†ç»„", groupID, err)
				continue
			}

			// æ›´æ–°æä¾›å•†é…ç½®ä¸­çš„APIå¯†é’¥
			p.providerRouter.UpdateProviderConfig(routeResult.ProviderConfig, apiKey)

			// Forward allowlisted request headers into provider headers (if not configured at group-level).
			p.applyForwardHeaders(c, routeResult.ProviderConfig)

			// è·å–ä¸è¯¥ API Key å¯¹åº”çš„æä¾›å•†å®ä¾‹ï¼ˆé¿å…åœ¨å¹¶å‘åœºæ™¯ä¸‹å…±äº«å¯å˜çš„ Configï¼‰
			if provider, err := p.providerManager.GetProvider(groupID, routeResult.ProviderConfig); err == nil {
				routeResult.Provider = provider
			} else {
				log.Printf("è·å–æä¾›å•†å®ä¾‹å¤±è´¥: group=%s key=%s err=%v", groupID, p.maskKey(apiKey), err)
				continue
			}

			// å°è¯•å¤„ç†è¯·æ±‚ï¼ˆæŒ‰åˆ†ç»„å¼ºåˆ¶è¦†ç›– request_paramsï¼›æ¯æ¬¡å°è¯•éƒ½ä½¿ç”¨ç‹¬ç«‹å‰¯æœ¬ï¼Œé¿å…è·¨åˆ†ç»„æ±¡æŸ“ï¼‰
			attemptReq := *req
			if req.Extra != nil {
				attemptReq.Extra = make(map[string]interface{}, len(req.Extra))
				for k, v := range req.Extra {
					attemptReq.Extra[k] = v
				}
			}
			attemptReq.ApplyRequestParams(routeResult.ProviderConfig.RequestParams)

			var success bool
			if attemptReq.Stream {
				success = p.handleStreamingRequest(c, &attemptReq, routeResult, apiKey, startTime)
			} else {
				success = p.handleNonStreamingRequest(c, &attemptReq, routeResult, apiKey, startTime)
			}

			if success {
				log.Printf("åˆ†ç»„é—´è½®æ¢é‡è¯•æˆåŠŸï¼šåˆ†ç»„ %s å¯†é’¥ %s", groupID, p.maskKey(apiKey))
				// æŠ¥å‘ŠæˆåŠŸä½¿ç”¨
				p.keyManager.ReportSuccess(groupID, apiKey)
				// å®æ—¶æ›´æ–°æ•°æ®åº“çŠ¶æ€
				p.updateKeyStatusInDatabase(groupID, apiKey, true, "")
				return true
			} else {
				log.Printf("åˆ†ç»„é—´è½®æ¢é‡è¯•å¤±è´¥ï¼šåˆ†ç»„ %s å¯†é’¥ %s", groupID, p.maskKey(apiKey))
				// æŠ¥å‘Šä½¿ç”¨å¤±è´¥
				p.keyManager.ReportError(groupID, apiKey, "è¯·æ±‚å¤±è´¥")
				// å®æ—¶æ›´æ–°æ•°æ®åº“çŠ¶æ€
				p.updateKeyStatusInDatabase(groupID, apiKey, false, "è¯·æ±‚å¤±è´¥")
			}

			// å¦‚æœå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œåœæ­¢
			if retryCount >= maxRetries {
				log.Printf("å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° %dï¼Œåœæ­¢é‡è¯•", maxRetries)
				return false
			}
		}

		// è¿›å…¥ä¸‹ä¸€è½®ï¼ˆå°è¯•æ¯ä¸ªåˆ†ç»„çš„ä¸‹ä¸€ä¸ªå¯†é’¥ï¼‰
		keyIndex++

		// æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¯ç”¨åˆ†ç»„éƒ½æ²¡æœ‰æ›´å¤šå¯†é’¥
		hasMoreKeys := false
		for _, groupID := range availableGroups {
			if keys, exists := groupKeys[groupID]; exists && keyIndex < len(keys) {
				hasMoreKeys = true
				break
			}
		}

		if !hasMoreKeys {
			log.Printf("æ‰€æœ‰å¯ç”¨åˆ†ç»„éƒ½æ²¡æœ‰æ›´å¤šå¯†é’¥å¯å°è¯•ï¼Œå½“å‰è½®æ¬¡: %d", keyIndex+1)
			break
		} else {
			log.Printf("è¿›å…¥ä¸‹ä¸€è½®é‡è¯•ï¼Œè½®æ¬¡: %d", keyIndex+1)
		}
	}

	log.Printf("åˆ†ç»„é—´è½®æ¢é‡è¯•å®Œæˆï¼Œå…±å°è¯• %d æ¬¡ï¼Œå…¨éƒ¨å¤±è´¥", retryCount)
	return false
}

// tryGroupWithAllKeys åœ¨æŒ‡å®šåˆ†ç»„å†…å°è¯•æ‰€æœ‰å¯ç”¨å¯†é’¥ï¼ˆä¿ç•™åŸå‡½æ•°ç”¨äºå…¶ä»–åœ°æ–¹è°ƒç”¨ï¼‰
func (p *MultiProviderProxy) tryGroupWithAllKeys(
	c *gin.Context,
	req *providers.ChatCompletionRequest,
	routeResult *router.RouteResult,
	startTime time.Time,
) bool {
	// æ£€æŸ¥RPMé™åˆ¶
	if !p.rpmLimiter.Allow(routeResult.GroupID) {
		c.JSON(http.StatusTooManyRequests, gin.H{
			"error": gin.H{
				"message": "Rate limit exceeded for the selected provider group",
				"type":    "rate_limit_error",
				"code":    "rpm_limit_exceeded",
			},
		})
		return false
	}

	// è·å–åˆ†ç»„çš„æ‰€æœ‰å¯ç”¨å¯†é’¥çŠ¶æ€
	groupStatus, exists := p.keyManager.GetGroupStatus(routeResult.GroupID)
	if !exists {
		log.Printf("åˆ†ç»„ %s ä¸å­˜åœ¨æˆ–æœªå¯ç”¨", routeResult.GroupID)
		return false
	}

	groupInfo := groupStatus.(map[string]interface{})
	keyStatuses, ok := groupInfo["key_statuses"].(map[string]*keymanager.KeyStatus)
	if !ok {
		log.Printf("æ— æ³•è·å–åˆ†ç»„ %s çš„å¯†é’¥çŠ¶æ€", routeResult.GroupID)
		return false
	}

	// æŒ‰ä¼˜å…ˆçº§æ’åºå¯†é’¥ï¼šæ´»è·ƒä¸”æœ‰æ•ˆçš„å¯†é’¥ä¼˜å…ˆ
	sortedKeys := p.sortKeysByPriority(keyStatuses)

	log.Printf("åˆ†ç»„ %s å†…å¼€å§‹å°è¯• %d ä¸ªå¯ç”¨å¯†é’¥", routeResult.GroupID, len(sortedKeys))

	// ä¾æ¬¡å°è¯•æ¯ä¸ªå¯†é’¥
	for i, apiKey := range sortedKeys {
		log.Printf("å°è¯•åˆ†ç»„ %s å†…ç¬¬ %d/%d ä¸ªå¯†é’¥: %s", routeResult.GroupID, i+1, len(sortedKeys), p.maskKey(apiKey))

		// æ›´æ–°æä¾›å•†é…ç½®ä¸­çš„APIå¯†é’¥
		p.providerRouter.UpdateProviderConfig(routeResult.ProviderConfig, apiKey)

		// Forward allowlisted request headers into provider headers (if not configured at group-level).
		p.applyForwardHeaders(c, routeResult.ProviderConfig)

		// è·å–ä¸è¯¥ API Key å¯¹åº”çš„æä¾›å•†å®ä¾‹ï¼ˆé¿å…åœ¨å¹¶å‘åœºæ™¯ä¸‹å…±äº«å¯å˜çš„ Configï¼‰
		if provider, err := p.providerManager.GetProvider(routeResult.GroupID, routeResult.ProviderConfig); err == nil {
			routeResult.Provider = provider
		} else {
			log.Printf("è·å–æä¾›å•†å®ä¾‹å¤±è´¥: group=%s key=%s err=%v", routeResult.GroupID, p.maskKey(apiKey), err)
			continue
		}

		// å°è¯•å¤„ç†è¯·æ±‚ï¼ˆæŒ‰åˆ†ç»„å¼ºåˆ¶è¦†ç›– request_paramsï¼›æ¯æ¬¡å°è¯•éƒ½ä½¿ç”¨ç‹¬ç«‹å‰¯æœ¬ï¼Œé¿å…è·¨åˆ†ç»„æ±¡æŸ“ï¼‰
		attemptReq := *req
		if req.Extra != nil {
			attemptReq.Extra = make(map[string]interface{}, len(req.Extra))
			for k, v := range req.Extra {
				attemptReq.Extra[k] = v
			}
		}
		attemptReq.ApplyRequestParams(routeResult.ProviderConfig.RequestParams)

		var success bool
		if attemptReq.Stream {
			success = p.handleStreamingRequest(c, &attemptReq, routeResult, apiKey, startTime)
		} else {
			success = p.handleNonStreamingRequest(c, &attemptReq, routeResult, apiKey, startTime)
		}

		if success {
			log.Printf("åˆ†ç»„ %s å¯†é’¥ %s è¯·æ±‚æˆåŠŸ", routeResult.GroupID, p.maskKey(apiKey))
			// æŠ¥å‘ŠæˆåŠŸä½¿ç”¨
			p.keyManager.ReportSuccess(routeResult.GroupID, apiKey)
			// å®æ—¶æ›´æ–°æ•°æ®åº“çŠ¶æ€
			p.updateKeyStatusInDatabase(routeResult.GroupID, apiKey, true, "")
			return true
		} else {
			log.Printf("åˆ†ç»„ %s å¯†é’¥ %s è¯·æ±‚å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ª", routeResult.GroupID, p.maskKey(apiKey))
			// æŠ¥å‘Šä½¿ç”¨å¤±è´¥
			p.keyManager.ReportError(routeResult.GroupID, apiKey, "è¯·æ±‚å¤±è´¥")
			// å®æ—¶æ›´æ–°æ•°æ®åº“çŠ¶æ€
			p.updateKeyStatusInDatabase(routeResult.GroupID, apiKey, false, "è¯·æ±‚å¤±è´¥")
		}
	}

	log.Printf("åˆ†ç»„ %s å†…æ‰€æœ‰ %d ä¸ªå¯†é’¥å‡å·²å°è¯•ï¼Œå…¨éƒ¨å¤±è´¥", routeResult.GroupID, len(sortedKeys))
	return false
}

// sortKeysByPriority æŒ‰ä¼˜å…ˆçº§æ’åºå¯†é’¥
func (p *MultiProviderProxy) sortKeysByPriority(keyStatuses map[string]*keymanager.KeyStatus) []string {
	type keyPriority struct {
		key      string
		priority int
		lastUsed time.Time
	}

	var priorities []keyPriority
	now := time.Now()

	for key, status := range keyStatuses {
		if !status.IsActive {
			continue // è·³è¿‡éæ´»è·ƒå¯†é’¥
		}

		// è·³è¿‡åœ¨é™æµå†·å´æœŸå†…çš„å¯†é’¥
		if !status.RateLimitUntil.IsZero() && now.Before(status.RateLimitUntil) {
			continue
		}

		priority := 0

		// æœ‰æ•ˆçš„å¯†é’¥ä¼˜å…ˆçº§æ›´é«˜
		if status.IsValid != nil && *status.IsValid {
			priority += 100
		}

		// é”™è¯¯è¾ƒå°‘çš„å¯†é’¥ä¼˜å…ˆçº§æ›´é«˜
		priority -= int(status.ErrorCount) * 5

		// é™æµæ¬¡æ•°è¾ƒå°‘çš„å¯†é’¥ä¼˜å…ˆçº§æ›´é«˜ï¼ˆä½†ä¸å¦‚é”™è¯¯é‚£ä¹ˆä¸¥é‡ï¼‰
		priority -= int(status.RateLimitCount) * 2

		// æœ€è¿‘ä½¿ç”¨è¾ƒå°‘çš„å¯†é’¥ä¼˜å…ˆçº§æ›´é«˜ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
		if time.Since(status.LastUsed) > time.Hour {
			priority += 10
		}

		// æœ€è¿‘æ²¡æœ‰è¢«é™æµçš„å¯†é’¥ä¼˜å…ˆçº§æ›´é«˜
		if !status.LastRateLimitAt.IsZero() && time.Since(status.LastRateLimitAt) < 30*time.Minute {
			priority -= 20 // æœ€è¿‘30åˆ†é’Ÿå†…è¢«é™æµè¿‡ï¼Œé™ä½ä¼˜å…ˆçº§
		}

		priorities = append(priorities, keyPriority{
			key:      key,
			priority: priority,
			lastUsed: status.LastUsed,
		})
	}

	// æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆé«˜ä¼˜å…ˆçº§åœ¨å‰ï¼‰
	for i := 0; i < len(priorities)-1; i++ {
		for j := i + 1; j < len(priorities); j++ {
			if priorities[i].priority < priorities[j].priority {
				priorities[i], priorities[j] = priorities[j], priorities[i]
			}
		}
	}

	var sortedKeys []string
	for _, p := range priorities {
		sortedKeys = append(sortedKeys, p.key)
	}

	return sortedKeys
}

// updateKeyStatusInDatabase å®æ—¶æ›´æ–°æ•°æ®åº“ä¸­çš„å¯†é’¥çŠ¶æ€
func (p *MultiProviderProxy) updateKeyStatusInDatabase(groupID, apiKey string, isSuccess bool, errorMsg string) {
	if p.database == nil {
		return
	}

	go func() {
		if err := p.database.UpdateAPIKeyUsageStats(groupID, apiKey, isSuccess, 0, errorMsg); err != nil {
			log.Printf("Failed to update key status in database: %v", err)
		}
	}()
}

// maskKey æ©ç æ˜¾ç¤ºå¯†é’¥
func (p *MultiProviderProxy) maskKey(key string) string {
	if len(key) <= 8 {
		return "****"
	}
	return key[:4] + "****" + key[len(key)-4:]
}

// handleNonStreamingRequestWithRetry å¤„ç†éæµå¼è¯·æ±‚ï¼ˆæ”¯æŒé‡è¯•ï¼‰
func (p *MultiProviderProxy) handleNonStreamingRequestWithRetry(
	c *gin.Context,
	req *providers.ChatCompletionRequest,
	routeResult *router.RouteResult,
	apiKey string,
	startTime time.Time,
) bool {
	return p.handleNonStreamingRequest(c, req, routeResult, apiKey, startTime)
}

// handleNonStreamingRequest å¤„ç†éæµå¼è¯·æ±‚
func (p *MultiProviderProxy) handleNonStreamingRequest(
	c *gin.Context,
	req *providers.ChatCompletionRequest,
	routeResult *router.RouteResult,
	apiKey string,
	startTime time.Time,
) bool {
	// åˆ›å»ºå¸¦æœ‰é•¿è¶…æ—¶çš„contextï¼Œé¿å…è¯·æ±‚è¶…æ—¶
	ctx, cancel := context.WithTimeout(context.Background(), 300*time.Second)
	defer cancel()

	// åº”ç”¨æ¨¡å‹åç§°æ˜ å°„
	originalModel := req.Model
	req.Model = p.providerRouter.ResolveModelName(req.Model, routeResult.GroupID)

	// è¾“å‡ºè¯¦ç»†çš„APIè°ƒç”¨ä¿¡æ¯ç”¨äºè°ƒè¯•
	log.Printf("ğŸš€ å‘é€APIè¯·æ±‚ - åˆ†ç»„: %s, æ¨¡å‹: %s, BaseURL: %s, ProviderType: %s",
		routeResult.GroupID, req.Model, routeResult.ProviderConfig.BaseURL, routeResult.ProviderConfig.ProviderType)
	log.Printf("ğŸ“‹ è¯·æ±‚å‚æ•° - MaxTokens: %v, Temperature: %v, TopP: %v, Messages: %d",
		req.MaxTokens, req.Temperature, req.TopP, len(req.Messages))
	log.Printf("ğŸ”‘ Headers - %v", routeResult.ProviderConfig.Headers)

	// å‘é€è¯·æ±‚åˆ°æä¾›å•†
	response, err := routeResult.Provider.ChatCompletion(ctx, req)

	// æ¢å¤åŸå§‹æ¨¡å‹åç§°ç”¨äºæ—¥å¿—è®°å½•
	req.Model = originalModel
	if err != nil {
		log.Printf("Provider request failed: %v", err)
		p.keyManager.ReportError(routeResult.GroupID, apiKey, err.Error())

		// è®°å½•é”™è¯¯æ—¥å¿—
		if p.requestLogger != nil {
			proxyKeyName, proxyKeyID := p.getProxyKeyInfo(c)
			reqBody, _ := json.Marshal(req)
			clientIP := logger.GetClientIP(c)
			p.requestLogger.LogRequest(proxyKeyName, proxyKeyID, routeResult.GroupID, apiKey, req.Model, string(reqBody), "", clientIP, 502, false, time.Since(startTime), err)
		}

		c.JSON(http.StatusBadGateway, gin.H{
			"error": gin.H{
				"message": "Failed to connect to provider",
				"type":    "connection_error",
				"code":    "upstream_error",
			},
		})
		return false
	}

	// æŠ¥å‘ŠæˆåŠŸ
	p.keyManager.ReportSuccess(routeResult.GroupID, apiKey)

	// æ£€æŸ¥æ˜¯å¦éœ€è¦è¿”å›åŸç”Ÿå“åº”æ ¼å¼
	var finalResponse interface{} = response
	if p.shouldUseNativeResponse(routeResult.GroupID, c) {
		// è·å–åŸç”Ÿå“åº”
		nativeResponse, err := p.getNativeResponse(routeResult.Provider, response)
		if err != nil {
			log.Printf("Failed to get native response: %v", err)
			// å¦‚æœè·å–åŸç”Ÿå“åº”å¤±è´¥ï¼Œä»ç„¶è¿”å›æ ‡å‡†æ ¼å¼
		} else {
			finalResponse = nativeResponse
		}
	}

	// è®°å½•æˆåŠŸæ—¥å¿—
	if p.requestLogger != nil {
		proxyKeyName, proxyKeyID := p.getProxyKeyInfo(c)
		reqBody, _ := json.Marshal(req)
		respBody, _ := json.Marshal(finalResponse)
		clientIP := logger.GetClientIP(c)
		p.requestLogger.LogRequest(proxyKeyName, proxyKeyID, routeResult.GroupID, apiKey, req.Model, string(reqBody), string(respBody), clientIP, 200, false, time.Since(startTime), nil)
	}

	// è¿”å›å“åº”
	c.JSON(http.StatusOK, finalResponse)
	return true
}

// handleStreamingRequestWithRetry å¤„ç†æµå¼è¯·æ±‚ï¼ˆæ”¯æŒé‡è¯•ï¼‰
func (p *MultiProviderProxy) handleStreamingRequestWithRetry(
	c *gin.Context,
	req *providers.ChatCompletionRequest,
	routeResult *router.RouteResult,
	apiKey string,
	startTime time.Time,
) bool {
	return p.handleStreamingRequest(c, req, routeResult, apiKey, startTime)
}

// handleStreamingRequest å¤„ç†æµå¼è¯·æ±‚
func (p *MultiProviderProxy) handleStreamingRequest(
	c *gin.Context,
	req *providers.ChatCompletionRequest,
	routeResult *router.RouteResult,
	apiKey string,
	startTime time.Time,
) bool {
	// åˆ›å»ºå¸¦æœ‰é•¿è¶…æ—¶çš„contextï¼Œé¿å…æµå¼è¯·æ±‚è¶…æ—¶
	ctx, cancel := context.WithTimeout(context.Background(), 300*time.Second)
	defer cancel()

	// åº”ç”¨æ¨¡å‹åç§°æ˜ å°„
	originalModel := req.Model
	req.Model = p.providerRouter.ResolveModelName(req.Model, routeResult.GroupID)

	// è®¾ç½®æµå¼å“åº”å¤´
	c.Header("Content-Type", "text/event-stream")
	c.Header("Cache-Control", "no-cache")
	c.Header("Connection", "keep-alive")
	c.Header("Access-Control-Allow-Origin", "*")

	// æ ¹æ®é…ç½®é€‰æ‹©æµå¼å“åº”ç±»å‹
	var streamChan <-chan providers.StreamResponse
	var err error

	if p.shouldUseNativeResponse(routeResult.GroupID, c) {
		// ä½¿ç”¨åŸç”Ÿæ ¼å¼æµå¼å“åº”
		streamChan, err = routeResult.Provider.ChatCompletionStreamNative(ctx, req)
	} else {
		// ä½¿ç”¨æ ‡å‡†æ ¼å¼æµå¼å“åº”
		streamChan, err = routeResult.Provider.ChatCompletionStream(ctx, req)
	}

	// æ¢å¤åŸå§‹æ¨¡å‹åç§°ç”¨äºæ—¥å¿—è®°å½•
	req.Model = originalModel
	if err != nil {
		log.Printf("Provider streaming request failed: %v", err)
		p.keyManager.ReportError(routeResult.GroupID, apiKey, err.Error())

		// è®°å½•é”™è¯¯æ—¥å¿—
		if p.requestLogger != nil {
			proxyKeyName, proxyKeyID := p.getProxyKeyInfo(c)
			reqBody, _ := json.Marshal(req)
			clientIP := logger.GetClientIP(c)
			p.requestLogger.LogRequest(proxyKeyName, proxyKeyID, routeResult.GroupID, apiKey, req.Model, string(reqBody), "", clientIP, 502, true, time.Since(startTime), err)
		}

		c.JSON(http.StatusBadGateway, gin.H{
			"error": gin.H{
				"message": "Failed to connect to provider",
				"type":    "connection_error",
				"code":    "upstream_error",
			},
		})
		return false
	}

	// è·å–å“åº”å†™å…¥å™¨
	w := c.Writer
	flusher, ok := w.(http.Flusher)
	if !ok {
		log.Printf("Streaming not supported")
		c.JSON(http.StatusInternalServerError, gin.H{
			"error": gin.H{
				"message": "Streaming not supported",
				"type":    "internal_error",
			},
		})
		return false
	}

	// å¤„ç†æµå¼æ•°æ®
	hasData := false
	responseBuffer := make([]byte, 0, 1024)
	lastChunks := make([][]byte, 0, 10) // ä¿å­˜æœ€å10ä¸ªchunkç”¨äºtokenæå–

	for streamResp := range streamChan {
		if streamResp.Error != nil {
			log.Printf("Stream error: %v", streamResp.Error)
			p.keyManager.ReportError(routeResult.GroupID, apiKey, streamResp.Error.Error())
			break
		}

		if len(streamResp.Data) > 0 {
			hasData = true
			w.Write(streamResp.Data)
			flusher.Flush()

			// æ”¶é›†å“åº”æ•°æ®ç”¨äºæ—¥å¿—è®°å½•
			if len(responseBuffer) < 5000 { // å‡å°‘å‰é¢å†…å®¹çš„è®°å½•
				responseBuffer = append(responseBuffer, streamResp.Data...)
			}

			// ä¿å­˜æœ€åçš„chunkï¼Œç”¨äºtokenæå–
			lastChunks = append(lastChunks, streamResp.Data)
			if len(lastChunks) > 10 {
				lastChunks = lastChunks[1:] // ä¿æŒæœ€å10ä¸ªchunk
			}
		}

		if streamResp.Done {
			break
		}
	}

	// å°†æœ€åçš„chunkæ·»åŠ åˆ°å“åº”ç¼“å†²åŒºï¼Œç¡®ä¿åŒ…å«tokenä¿¡æ¯
	for _, chunk := range lastChunks {
		responseBuffer = append(responseBuffer, chunk...)
	}

	duration := time.Since(startTime)

	// å¦‚æœæ¥æ”¶åˆ°æ•°æ®ï¼ŒæŠ¥å‘ŠæˆåŠŸ
	if hasData {
		p.keyManager.ReportSuccess(routeResult.GroupID, apiKey)

		// è®°å½•æˆåŠŸæ—¥å¿—
		if p.requestLogger != nil {
			proxyKeyName, proxyKeyID := p.getProxyKeyInfo(c)
			reqBody, _ := json.Marshal(req)
			clientIP := logger.GetClientIP(c)
			p.requestLogger.LogRequest(proxyKeyName, proxyKeyID, routeResult.GroupID, apiKey, req.Model, string(reqBody), string(responseBuffer), clientIP, 200, true, duration, nil)
		}
		return true
	}

	return false
}

// getProxyKeyInfo è·å–ä»£ç†å¯†é’¥ä¿¡æ¯
func (p *MultiProviderProxy) getProxyKeyInfo(c *gin.Context) (string, string) {
	// é¦–å…ˆå°è¯•ä»ä¸Šä¸‹æ–‡ä¸­è·å–å·²è®¾ç½®çš„ä»£ç†å¯†é’¥ä¿¡æ¯
	if name, exists := c.Get("proxy_key_name"); exists {
		if nameStr, ok := name.(string); ok {
			if id, exists := c.Get("proxy_key_id"); exists {
				if idStr, ok := id.(string); ok {
					return nameStr, idStr
				}
			}
			return nameStr, "unknown"
		}
	}

	// å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»key_infoä¸­è·å–
	if keyInfo, exists := c.Get("key_info"); exists {
		if proxyKey, ok := keyInfo.(*logger.ProxyKey); ok {
			// è®¾ç½®åˆ°ä¸Šä¸‹æ–‡ä¸­ä»¥ä¾¿åç»­ä½¿ç”¨
			c.Set("proxy_key_name", proxyKey.Name)
			c.Set("proxy_key_id", proxyKey.ID)

			// æ›´æ–°ä»£ç†å¯†é’¥ä½¿ç”¨æ¬¡æ•°
			if p.proxyKeyManager != nil {
				p.proxyKeyManager.UpdateUsage(proxyKey.Key)
			}

			return proxyKey.Name, proxyKey.ID
		}
	}

	return "Unknown", "unknown"
}

// GetProviderRouter è·å–æä¾›å•†è·¯ç”±å™¨
func (p *MultiProviderProxy) GetProviderRouter() *router.ProviderRouter {
	return p.providerRouter
}

// GetProviderManager è·å–æä¾›å•†ç®¡ç†å™¨
func (p *MultiProviderProxy) GetProviderManager() *providers.ProviderManager {
	return p.providerManager
}

// HandleModels å¤„ç†æ¨¡å‹åˆ—è¡¨è¯·æ±‚
func (p *MultiProviderProxy) HandleModels(c *gin.Context) {
	// æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†ç‰¹å®šçš„æä¾›å•†åˆ†ç»„
	groupID := c.Query("provider_group")

	if groupID != "" {
		// è·å–ç‰¹å®šåˆ†ç»„çš„æ¨¡å‹
		p.handleGroupModels(c, groupID)
	} else {
		// è·å–æ‰€æœ‰åˆ†ç»„çš„æ¨¡å‹
		p.handleAllModels(c)
	}
}

// handleGroupModels å¤„ç†ç‰¹å®šåˆ†ç»„çš„æ¨¡å‹åˆ—è¡¨è¯·æ±‚
func (p *MultiProviderProxy) handleGroupModels(c *gin.Context, groupID string) {
	// è·å–åˆ†ç»„ä¿¡æ¯
	group, exists := p.providerRouter.GetGroupInfo(groupID)
	if !exists {
		c.JSON(http.StatusNotFound, gin.H{
			"error": gin.H{
				"message": fmt.Sprintf("Provider group '%s' not found", groupID),
				"type":    "invalid_request_error",
				"code":    "group_not_found",
			},
		})
		return
	}

	if !group.Enabled {
		c.JSON(http.StatusBadRequest, gin.H{
			"error": gin.H{
				"message": fmt.Sprintf("Provider group '%s' is disabled", groupID),
				"type":    "invalid_request_error",
				"code":    "group_disabled",
			},
		})
		return
	}

	// è·å–APIå¯†é’¥
	apiKey, err := p.keyManager.GetNextKeyForGroup(groupID)
	if err != nil {
		c.JSON(http.StatusServiceUnavailable, gin.H{
			"error": gin.H{
				"message": "No available API keys for this group",
				"type":    "service_unavailable",
				"code":    "no_api_keys",
			},
		})
		return
	}

	// åˆ›å»ºæä¾›å•†é…ç½®
	providerConfig := &providers.ProviderConfig{
		BaseURL:         group.BaseURL,
		APIKey:          apiKey,
		Timeout:         group.Timeout,
		MaxRetries:      group.MaxRetries,
		Headers:         group.Headers,
		ProviderType:    group.ProviderType,
		RequestParams:   group.RequestParams,
		UseResponsesAPI: group.UseResponsesAPI,
	}

	// è·å–æä¾›å•†å®ä¾‹
	provider, err := p.providerManager.GetProvider(groupID, providerConfig)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{
			"error": gin.H{
				"message": "Failed to get provider instance",
				"type":    "internal_error",
				"code":    "provider_error",
			},
		})
		return
	}

	// è·å–æ¨¡å‹åˆ—è¡¨
	ctx := c.Request.Context()
	rawModels, err := provider.GetModels(ctx)
	if err != nil {
		log.Printf("Failed to get models from provider %s: %v", groupID, err)
		p.keyManager.ReportError(groupID, apiKey, err.Error())
		c.JSON(http.StatusBadGateway, gin.H{
			"error": gin.H{
				"message": "Failed to get models from provider",
				"type":    "connection_error",
				"code":    "upstream_error",
			},
		})
		return
	}

	// æŠ¥å‘ŠæˆåŠŸ
	p.keyManager.ReportSuccess(groupID, apiKey)

	// æ ‡å‡†åŒ–æ¨¡å‹æ•°æ®æ ¼å¼
	standardizedModels := p.standardizeModelsResponse(rawModels, group.ProviderType)

	// æ·»åŠ æ¨¡å‹åˆ«ååˆ°æ¨¡å‹åˆ—è¡¨ä¸­
	var enhancedModels interface{}
	if modelSlice, ok := standardizedModels.([]map[string]interface{}); ok {
		enhancedModels = p.addModelAliases(modelSlice, groupID)
	} else {
		enhancedModels = standardizedModels
	}

	// ä¸ºäº†ä¸å‰ç«¯æœŸæœ›çš„æ ¼å¼ä¸€è‡´ï¼Œå°†å•ä¸ªæä¾›å•†çš„å“åº”åŒ…è£…æˆä¸æ‰€æœ‰æä¾›å•†ç›¸åŒçš„æ ¼å¼
	response := gin.H{
		"object": "list",
		"data": map[string]interface{}{
			groupID: map[string]interface{}{
				"group_name":    group.Name,
				"provider_type": group.ProviderType,
				"models":        enhancedModels,
			},
		},
	}

	// è¿”å›æ¨¡å‹åˆ—è¡¨
	c.JSON(http.StatusOK, response)
}

// handleAllModels å¤„ç†æ‰€æœ‰åˆ†ç»„çš„æ¨¡å‹åˆ—è¡¨è¯·æ±‚
func (p *MultiProviderProxy) handleAllModels(c *gin.Context) {
	allModels := make(map[string]interface{})

	// è·å–æ‰€æœ‰å¯ç”¨çš„åˆ†ç»„
	enabledGroups := p.providerRouter.GetAvailableGroups()

	for groupID, group := range enabledGroups {
		// è·å–APIå¯†é’¥
		apiKey, err := p.keyManager.GetNextKeyForGroup(groupID)
		if err != nil {
			log.Printf("Failed to get API key for group %s: %v", groupID, err)
			continue
		}

		// åˆ›å»ºæä¾›å•†é…ç½®
		providerConfig := &providers.ProviderConfig{
			BaseURL:         group.BaseURL,
			APIKey:          apiKey,
			Timeout:         group.Timeout,
			MaxRetries:      group.MaxRetries,
			Headers:         group.Headers,
			ProviderType:    group.ProviderType,
			RequestParams:   group.RequestParams,
			UseResponsesAPI: group.UseResponsesAPI,
		}

		// è·å–æä¾›å•†å®ä¾‹
		provider, err := p.providerManager.GetProvider(groupID, providerConfig)
		if err != nil {
			log.Printf("Failed to get provider for group %s: %v", groupID, err)
			continue
		}

		// è·å–æ¨¡å‹åˆ—è¡¨
		ctx := c.Request.Context()
		rawModels, err := provider.GetModels(ctx)
		if err != nil {
			log.Printf("Failed to get models from provider %s: %v", groupID, err)
			p.keyManager.ReportError(groupID, apiKey, err.Error())
			continue
		}

		// æŠ¥å‘ŠæˆåŠŸ
		p.keyManager.ReportSuccess(groupID, apiKey)

		// æ ‡å‡†åŒ–æ¨¡å‹æ•°æ®æ ¼å¼
		standardizedModels := p.standardizeModelsResponse(rawModels, group.ProviderType)

		// æ·»åŠ æ¨¡å‹åˆ«ååˆ°æ¨¡å‹åˆ—è¡¨ä¸­
		var enhancedModels interface{}
		if modelSlice, ok := standardizedModels.([]map[string]interface{}); ok {
			enhancedModels = p.addModelAliases(modelSlice, groupID)
		} else {
			enhancedModels = standardizedModels
		}

		// æ·»åŠ åˆ°ç»“æœä¸­
		allModels[groupID] = map[string]interface{}{
			"group_name":    group.Name,
			"provider_type": group.ProviderType,
			"models":        enhancedModels,
		}
	}

	// è¿”å›æ‰€æœ‰æ¨¡å‹
	c.JSON(http.StatusOK, gin.H{
		"object": "list",
		"data":   allModels,
	})
}

// StandardizeModelsResponse æ ‡å‡†åŒ–ä¸åŒæä¾›å•†çš„æ¨¡å‹å“åº”æ ¼å¼ï¼ˆå…¬å¼€æ–¹æ³•ï¼‰
func (p *MultiProviderProxy) StandardizeModelsResponse(rawModels interface{}, providerType string) interface{} {
	return p.standardizeModelsResponse(rawModels, providerType)
}

// standardizeModelsResponse æ ‡å‡†åŒ–ä¸åŒæä¾›å•†çš„æ¨¡å‹å“åº”æ ¼å¼
func (p *MultiProviderProxy) standardizeModelsResponse(rawModels interface{}, providerType string) interface{} {
	switch providerType {
	case "openai", "azure_openai":
		// OpenAIæ ¼å¼å·²ç»æ˜¯æ ‡å‡†æ ¼å¼
		return rawModels

	case "gemini":
		// Geminiæ ¼å¼éœ€è¦è½¬æ¢
		return p.standardizeGeminiModels(rawModels)

	case "anthropic":
		// Anthropicæ ¼å¼éœ€è¦è½¬æ¢
		return p.standardizeAnthropicModels(rawModels)

	default:
		// é»˜è®¤å°è¯•OpenAIæ ¼å¼
		return rawModels
	}
}

// standardizeGeminiModels æ ‡å‡†åŒ–Geminiæ¨¡å‹å“åº”
func (p *MultiProviderProxy) standardizeGeminiModels(rawModels interface{}) interface{} {
	// å°è¯•è§£æGeminiå“åº”æ ¼å¼
	if modelsMap, ok := rawModels.(map[string]interface{}); ok {
		// æ£€æŸ¥æ˜¯å¦æœ‰dataå­—æ®µï¼ˆGeminiæä¾›å•†è¿”å›çš„æ ¼å¼ï¼‰
		if modelsArray, exists := modelsMap["data"]; exists {
			// å°è¯•å¤šç§ç±»å‹æ–­è¨€
			var models []map[string]interface{}
			var ok bool

			// é¦–å…ˆå°è¯• []map[string]interface{}
			if typedModels, typeOk := modelsArray.([]map[string]interface{}); typeOk {
				models = typedModels
				ok = true
			} else if interfaceModels, typeOk := modelsArray.([]interface{}); typeOk {
				// å¦‚æœæ˜¯ []interface{}ï¼Œå°è¯•è½¬æ¢æ¯ä¸ªå…ƒç´ 
				models = make([]map[string]interface{}, 0, len(interfaceModels))
				for _, item := range interfaceModels {
					if modelMap, mapOk := item.(map[string]interface{}); mapOk {
						models = append(models, modelMap)
					}
				}
				ok = len(models) > 0
			}

			if ok && len(models) > 0 {
				// è½¬æ¢ä¸ºOpenAIæ ¼å¼
				standardModels := make([]map[string]interface{}, 0)
				for _, modelMap := range models {
					// æå–æ¨¡å‹ID - Geminiæä¾›å•†å·²ç»å¤„ç†è¿‡äº†ï¼Œç›´æ¥ä½¿ç”¨idå­—æ®µ
					var modelID string
					if id, exists := modelMap["id"]; exists {
						if idStr, idOk := id.(string); idOk {
							modelID = idStr
						}
					}

					if modelID != "" {
						standardModel := map[string]interface{}{
							"id":       modelID,
							"object":   "model",
							"owned_by": "google",
						}

						// æ·»åŠ å…¶ä»–å¯ç”¨ä¿¡æ¯
						if created, exists := modelMap["created"]; exists {
							standardModel["created"] = created
						}

						standardModels = append(standardModels, standardModel)
					}
				}

				return map[string]interface{}{
					"object": "list",
					"data":   standardModels,
				}
			}
		} else {
			// æ£€æŸ¥æ˜¯å¦æœ‰modelså­—æ®µï¼ˆåŸå§‹Google APIæ ¼å¼ï¼‰
			if modelsArray, exists := modelsMap["models"]; exists {
				if models, ok := modelsArray.([]interface{}); ok {
					// è½¬æ¢ä¸ºOpenAIæ ¼å¼
					standardModels := make([]map[string]interface{}, 0)
					for _, model := range models {
						if modelMap, ok := model.(map[string]interface{}); ok {
							// æå–æ¨¡å‹åç§°
							var modelID string
							if name, exists := modelMap["name"]; exists {
								if nameStr, ok := name.(string); ok {
									// Geminiæ¨¡å‹åç§°æ ¼å¼: "models/gemini-pro"
									parts := strings.Split(nameStr, "/")
									if len(parts) > 1 {
										modelID = parts[len(parts)-1]
									} else {
										modelID = nameStr
									}
								}
							}

							if modelID != "" {
								standardModel := map[string]interface{}{
									"id":       modelID,
									"object":   "model",
									"owned_by": "google",
								}

								// æ·»åŠ å…¶ä»–å¯ç”¨ä¿¡æ¯
								if displayName, exists := modelMap["displayName"]; exists {
									standardModel["display_name"] = displayName
								}
								if description, exists := modelMap["description"]; exists {
									standardModel["description"] = description
								}

								standardModels = append(standardModels, standardModel)
							}
						}
					}

					return map[string]interface{}{
						"object": "list",
						"data":   standardModels,
					}
				}
			}
		}
	}

	// å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
	return map[string]interface{}{
		"object": "list",
		"data":   []interface{}{},
	}
}

// standardizeAnthropicModels æ ‡å‡†åŒ–Anthropicæ¨¡å‹å“åº”
func (p *MultiProviderProxy) standardizeAnthropicModels(rawModels interface{}) interface{} {
	// Anthropicé€šå¸¸ä¸æä¾›æ¨¡å‹åˆ—è¡¨APIï¼Œè¿”å›é¢„å®šä¹‰çš„æ¨¡å‹
	predefinedModels := []map[string]interface{}{
		{
			"id":       "claude-3-sonnet-20240229",
			"object":   "model",
			"owned_by": "anthropic",
		},
		{
			"id":       "claude-3-opus-20240229",
			"object":   "model",
			"owned_by": "anthropic",
		},
		{
			"id":       "claude-3-haiku-20240307",
			"object":   "model",
			"owned_by": "anthropic",
		},
		{
			"id":       "claude-2.1",
			"object":   "model",
			"owned_by": "anthropic",
		},
		{
			"id":       "claude-2.0",
			"object":   "model",
			"owned_by": "anthropic",
		},
	}

	return map[string]interface{}{
		"object": "list",
		"data":   predefinedModels,
	}
}

// getProviderGroup è·å–æä¾›å•†åˆ†ç»„ä¿¡æ¯
func (p *MultiProviderProxy) getProviderGroup(c *gin.Context, model string) string {
	// å°è¯•ä»ä¸Šä¸‹æ–‡ä¸­è·å–åˆ†ç»„ä¿¡æ¯
	if groupID, exists := c.Get("provider_group"); exists {
		if groupStr, ok := groupID.(string); ok {
			return groupStr
		}
	}

	// å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ï¼Œå°è¯•æ ¹æ®æ¨¡å‹æ¨æ–­åˆ†ç»„
	if group, groupID := p.config.GetGroupByModel(model); group != nil {
		return groupID
	}

	// é»˜è®¤è¿”å›ç©ºå­—ç¬¦ä¸²
	return ""
}

// addModelAliases ä¸ºæ¨¡å‹åˆ—è¡¨æ·»åŠ åˆ«åä¿¡æ¯
func (p *MultiProviderProxy) addModelAliases(models []map[string]interface{}, groupID string) []map[string]interface{} {
	group, exists := p.config.UserGroups[groupID]
	if !exists || len(group.ModelMappings) == 0 {
		return models
	}

	var enhancedModels []map[string]interface{}

	// å¤„ç†æ¯ä¸ªåŸå§‹æ¨¡å‹
	for _, model := range models {
		modelID, ok := model["id"].(string)
		if !ok {
			enhancedModels = append(enhancedModels, model)
			continue
		}

		// æ£€æŸ¥æ˜¯å¦æœ‰åˆ«åæ˜ å°„åˆ°è¿™ä¸ªåŸå§‹æ¨¡å‹
		var aliases []string
		for alias, originalModel := range group.ModelMappings {
			if originalModel == modelID {
				aliases = append(aliases, alias)
			}
		}

		if len(aliases) > 0 {
			// å¦‚æœæœ‰åˆ«åï¼Œä¸ºæ¯ä¸ªåˆ«ååˆ›å»ºæ¡ç›®
			for _, alias := range aliases {
				aliasModel := make(map[string]interface{})
				for k, v := range model {
					aliasModel[k] = v
				}
				aliasModel["id"] = alias
				aliasModel["original_model"] = modelID
				aliasModel["is_alias"] = true
				enhancedModels = append(enhancedModels, aliasModel)
			}

			// ä¹Ÿä¿ç•™åŸå§‹æ¨¡å‹ï¼Œä½†æ ‡è®°å®ƒæœ‰åˆ«å
			originalModel := make(map[string]interface{})
			for k, v := range model {
				originalModel[k] = v
			}
			originalModel["has_aliases"] = aliases
			originalModel["is_original"] = true
			enhancedModels = append(enhancedModels, originalModel)
		} else {
			// æ²¡æœ‰åˆ«åçš„æ¨¡å‹ç›´æ¥æ·»åŠ 
			enhancedModels = append(enhancedModels, model)
		}
	}

	// æ·»åŠ é‚£äº›æ²¡æœ‰å¯¹åº”åŸå§‹æ¨¡å‹çš„åˆ«åï¼ˆå¯èƒ½æ˜¯è·¨åˆ†ç»„æ˜ å°„ï¼‰
	for alias, originalModel := range group.ModelMappings {
		// æ£€æŸ¥åŸå§‹æ¨¡å‹æ˜¯å¦åœ¨å½“å‰æ¨¡å‹åˆ—è¡¨ä¸­
		found := false
		for _, model := range models {
			if modelID, ok := model["id"].(string); ok && modelID == originalModel {
				found = true
				break
			}
		}

		// å¦‚æœåŸå§‹æ¨¡å‹ä¸åœ¨å½“å‰åˆ—è¡¨ä¸­ï¼Œåˆ›å»ºä¸€ä¸ªåˆ«åæ¡ç›®
		if !found {
			aliasModel := map[string]interface{}{
				"id":             alias,
				"object":         "model",
				"created":        0,
				"owned_by":       "alias",
				"original_model": originalModel,
				"is_alias":       true,
				"cross_group":    true, // æ ‡è®°ä¸ºè·¨åˆ†ç»„æ˜ å°„
			}
			enhancedModels = append(enhancedModels, aliasModel)
		}
	}

	return enhancedModels
}
